{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/image_captioning/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 13.5G/13.5G [04:48<00:00, 46.9MB/s]  \n",
      "Downloading data: 100%|██████████| 6.65G/6.65G [02:28<00:00, 44.7MB/s]\n",
      "Downloading data: 100%|██████████| 6.66G/6.66G [02:35<00:00, 42.9MB/s]\n",
      "Downloading data: 100%|██████████| 253M/253M [00:04<00:00, 60.1MB/s] \n",
      "Downloading data: 100%|██████████| 763k/763k [00:00<00:00, 78.2MB/s]\n",
      "Load images: 100%|██████████| 82783/82783 [00:00<00:00, 1242021.58it/s]\n",
      "Load captions data: 100%|██████████| 414113/414113 [00:00<00:00, 732664.73it/s]\n",
      "Generating train split: 82783 examples [00:13, 6234.69 examples/s]\n",
      "Load images: 100%|██████████| 40504/40504 [00:00<00:00, 1310172.13it/s]\n",
      "Load captions data: 100%|██████████| 202654/202654 [00:00<00:00, 1091333.18it/s]\n",
      "Generating validation split: 40504 examples [00:06, 6304.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the 2014 captions dataset\n",
    "dataset = load_dataset(\"shunk031/MSCOCO\", year=2014, coco_task=\"captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the training split\n",
    "train_dataset = dataset['train']\n",
    "# Access the validation split\n",
    "validation_dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A restaurant has modern wooden tables and chairs.', 'A long restaurant table with rattan rounded back chairs.', 'a long table with a plant on top of it surrounded with wooden chairs ', 'A long table with a flower arrangement in the middle for meetings', 'A table is adorned with wooden chairs with blue accents.']\n"
     ]
    }
   ],
   "source": [
    "# Display the first example in the training set\n",
    "first_example = train_dataset[0]\n",
    "image = first_example['image']\n",
    "captions = first_example['annotations']['caption']\n",
    "\n",
    "# Display the image and its captions\n",
    "image.show()\n",
    "print(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_captioning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
